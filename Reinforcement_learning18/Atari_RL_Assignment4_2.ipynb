{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "\n",
    "import os\n",
    "logdir='./Atari_Breakout/'\n",
    "logging_interval = 100\n",
    "animate_interval = logging_interval * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Use CUDA</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: True\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"Using CUDA: {}\".format(use_cuda))\n",
    "device   = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Create Environments</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-06-02 19:19:59,079] Making new env: Breakout-v0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"~/Courses_Repo18-20/Reinforcement_learning18/RL-Adventure-2/common\")\n",
    "\n",
    "from common import multiprocessing_env\n",
    "#from multiprocessing_env import SubprocVecEnv\n",
    "\n",
    "num_envs = 1\n",
    "#env_name = \"Pendulum-v0\"\n",
    "env_name = 'Breakout-v0' \n",
    "\n",
    "#def make_env():\n",
    "#    def _thunk():\n",
    "#        env = gym.make(env_name)\n",
    "#        return env\n",
    "#    return _thunk\n",
    "\n",
    "#envs = [make_env() for i in range(num_envs)]\n",
    "#envs = SubprocVecEnv(envs)\n",
    "\n",
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-06-02 19:19:59,378] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    }
   ],
   "source": [
    "VISUALIZE = True\n",
    "SEED = 0 \n",
    "MAX_PATH_LENGTH = 500 \n",
    "NUM_EPISODES = 12000\n",
    "if VISUALIZE:\n",
    "    if not os.path.exists(logdir):\n",
    "        os.mkdir(logdir)\n",
    "    env = gym.wrappers.Monitor(env, logdir, force=True, video_callable=lambda episode_id: episode_id%logging_interval==0)\n",
    "\n",
    "#Need to look through code more before setting this. \n",
    "#env._max_episode_steps = MAX_PATH_LENGTH\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Neural Network</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, num_in, num_out, hidden_size):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=num_in, out_channels=32, kernel_size=8, stride=4)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(in_features=7*7*64, out_features=hidden_size)\n",
    "        self.fc2 = nn.Linear(in_features=hidden_size, out_features=num_out)        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.normal_(m.weight, mean=0., std=0.1)\n",
    "        nn.init.constant_(m.bias, 0.1)\n",
    "\n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs, hidden_size, std=0.0):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        \n",
    "        self.critic = DQN(num_inputs, 1, hidden_size)\n",
    "        self.actor = DQN(num_inputs, num_outputs, hidden_size)\n",
    "        \n",
    "        self.log_std = nn.Parameter(torch.ones(1, num_outputs) * std)\n",
    "        \n",
    "        self.critic.apply(init_weights)\n",
    "        self.actor.apply(init_weights)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        value = self.critic(x)\n",
    "        mu    = self.actor(x)\n",
    "        std   = self.log_std.exp().expand_as(mu)\n",
    "        dist  = Normal(mu, std)\n",
    "        return dist, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, rewards[-1]))\n",
    "    plt.plot(rewards)\n",
    "    plt.show()\n",
    "    \n",
    "def test_env(vis=False):\n",
    "    try:\n",
    "        state = env.reset()\n",
    "    except:\n",
    "        while(True):\n",
    "            a, b, c, d = env.step(0)\n",
    "            if c:\n",
    "                break\n",
    "        state = env.reset()\n",
    "        \n",
    "    if vis: env.render()\n",
    "        \n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    state, _, _ = step(0)\n",
    "    while not done:\n",
    "#        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        dist, _ = model(state)\n",
    "        next_state, reward, done = step(np.argmax(dist.sample().cpu().numpy()))\n",
    "        state = next_state\n",
    "        if vis: env.render()\n",
    "        total_reward += reward\n",
    "    env.reset()\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>High-Dimensional Continuous Control Using Generalized Advantage Estimation</h1>\n",
    "<h3><a href=\"https://arxiv.org/abs/1506.02438\">Arxiv</a></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gae(next_value, rewards, masks, values, gamma=0.99, tau=0.95):\n",
    "    values = values + [next_value]\n",
    "    gae = 0\n",
    "    returns = []\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        delta = rewards[step] + gamma * values[step + 1] * masks[step] - values[step]\n",
    "        gae = delta + gamma * tau * masks[step] * gae\n",
    "        returns.insert(0, gae + values[step])\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# feed in 4 frames\n",
    "num_inputs  = 4\n",
    "\n",
    "# number of actions\n",
    "num_outputs = env.action_space.n\n",
    "print(num_outputs)\n",
    "\n",
    "#Hyper params:\n",
    "hidden_size = 512\n",
    "lr          = 1e-4\n",
    "num_steps   = 20\n",
    "\n",
    "model = ActorCritic(num_inputs, num_outputs, hidden_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def process_state(frame):\n",
    "    # rid of extra dim\n",
    "    img = np.reshape(frame, [210, 160, 3])\n",
    "    # convert to b/w\n",
    "    img = img[:, :, 0] * 0.299 + img[:, :, 1] * 0.587 + img[:, :, 2] * 0.114\n",
    "    # resize\n",
    "    img = Image.fromarray(img)\n",
    "    resized_screen = img.resize((84, 84), Image.BILINEAR)\n",
    "    resized_screen = np.array(resized_screen)\n",
    "    return np.reshape(resized_screen, [1,84,84])\n",
    "\n",
    "def stack(slist):\n",
    "    frames = np.zeros([4, 84, 84])\n",
    "    for i in range(4):\n",
    "#        frames[i, :, :] = process_state(slist[i].permute(0,3,1,2).cpu().numpy())\n",
    "        frames[i, :, :] = process_state(slist[i])\n",
    "    return torch.FloatTensor(frames.reshape([1,4,84,84])).to(device)\n",
    "\n",
    "def step(action):\n",
    "    states = []\n",
    "    reward = []\n",
    "    for i in range(4):\n",
    "        s, r, d, _ = env.step(action)\n",
    "#        print(s)\n",
    "        states.append(s)\n",
    "        reward.append(r)\n",
    "        if d:\n",
    "            for j in range(3-i):\n",
    "                states.append(s)\n",
    "            return stack(states), sum(reward)/len(reward), d\n",
    "    return stack(states), sum(reward)/len(reward), d\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_frames   = 1000000\n",
    "frame_idx    = 0\n",
    "test_rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f79e905e81cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframe_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mtest_rewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_rewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-f79e905e81cc>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframe_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mtest_rewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_rewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-7091d3d99f28>\u001b[0m in \u001b[0;36mtest_env\u001b[0;34m(vis)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#        state = torch.FloatTensor(state).unsqueeze(0).to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-36f13d2e7ced>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(action)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mstates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-36f13d2e7ced>\u001b[0m in \u001b[0;36mstack\u001b[0;34m(slist)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#        frames[i, :, :] = process_state(slist[i].permute(0,3,1,2).cpu().numpy())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mframes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m84\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m84\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-36f13d2e7ced>\u001b[0m in \u001b[0;36mprocess_state\u001b[0;34m(frame)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.299\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.587\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.114\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# resize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mresized_screen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m84\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m84\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBILINEAR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mresized_screen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresized_screen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2448\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2450\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfrombuffer\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   2401\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2403\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrombytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfrombytes\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   2334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2335\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2336\u001b[0;31m     \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2337\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfrombytes\u001b[0;34m(self, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m    783\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_getdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# create first \"state\"\n",
    "state = env.reset()\n",
    "state, _, _ = step(0)\n",
    "done = False\n",
    "\n",
    "while frame_idx < max_frames:\n",
    "\n",
    "    log_probs = []\n",
    "    values    = []\n",
    "    rewards   = []\n",
    "    masks     = []\n",
    "    entropy = 0\n",
    "    \n",
    "    if done:\n",
    "        state = env.reset()\n",
    "        state, _, _ = step(0)\n",
    "\n",
    "    for _ in range(num_steps):\n",
    "#        state = torch.FloatTensor(state).to(device)\n",
    "        dist, value = model(state)\n",
    "\n",
    "        action = dist.sample()\n",
    "#        print(action)\n",
    "#        print(state.size())\n",
    "        next_state, reward, done = step(np.argmax(action.cpu().numpy()))\n",
    "\n",
    "        log_prob = dist.log_prob(action)\n",
    "        entropy += dist.entropy().mean()\n",
    "        \n",
    "        log_probs.append(log_prob)\n",
    "        values.append(value)\n",
    "        rewards.append(torch.FloatTensor(np.array(reward)).unsqueeze(0).to(device))\n",
    "        masks.append(torch.FloatTensor(np.array(1 - done)).unsqueeze(0).to(device))\n",
    "        if done:\n",
    "            break\n",
    "        \n",
    "        state = next_state\n",
    "        frame_idx += 1\n",
    "        \n",
    "        if frame_idx % 1000 == 0:\n",
    "            test_rewards.append(np.mean([test_env() for _ in range(10)]))\n",
    "            plot(frame_idx, test_rewards)\n",
    "            \n",
    "#    next_state = torch.FloatTensor(next_state).to(device)\n",
    "    _, next_value = model(next_state)\n",
    "    returns = compute_gae(next_value, rewards, masks, values)\n",
    "    \n",
    "    log_probs = torch.cat(log_probs)\n",
    "    returns   = torch.cat(returns).detach()\n",
    "    values    = torch.cat(values)\n",
    "\n",
    "    advantage = returns - values\n",
    "\n",
    "    actor_loss  = -(log_probs * advantage.detach()).mean()\n",
    "    critic_loss = advantage.pow(2).mean()\n",
    "\n",
    "    loss = actor_loss + 0.5 * critic_loss - 0.001 * entropy\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'atari_breakout_6k.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported_model = ActorCritic(num_inputs, num_outputs, hidden_size).to(device)\n",
    "imported_model.load_state_dict(torch.load('atari_pong_18k.pt'))\n",
    "def test_import(vis=False):\n",
    "    try:\n",
    "        state = env.reset()\n",
    "    except:\n",
    "        while(True):\n",
    "            a, b, c, d = env.step(0)\n",
    "            if c:\n",
    "                break\n",
    "        state = env.reset()\n",
    "        \n",
    "    if vis: env.render()\n",
    "        \n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    state, _, _ = step(0)\n",
    "    while not done:\n",
    "#        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        dist, _ = imported_model(state)\n",
    "        next_state, reward, done = step(np.argmax(dist.sample().cpu().numpy()))\n",
    "        state = next_state\n",
    "        if vis: env.render()\n",
    "        total_reward += reward\n",
    "    env.reset()\n",
    "    return total_reward\n",
    "\n",
    "test_import(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "    a, b, c, d = env.step(0)\n",
    "    if c:\n",
    "        break\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
